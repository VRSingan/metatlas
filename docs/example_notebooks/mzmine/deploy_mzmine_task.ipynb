{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys, os\n",
    "sys.path.insert(0,'/global/homes/b/bpb/metatlas')\n",
    "\n",
    "sys.path.insert(1,'/global/project/projectdirs/metatlas/anaconda/lib/python2.7/site-packages' )\n",
    "\n",
    "\n",
    "import metatlas.metatlas_objects as metob\n",
    "from metatlas.helpers import mzmine_helpers as mzm\n",
    "from metatlas.helpers import dill2plots as dp\n",
    "from metatlas.helpers import metatlas_get_data_helper_fun as ma_data\n",
    "from metatlas.helpers import rt_corrector as rt_corrector\n",
    "from metatlas.helpers import chromatograms_mp_plots as cp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing as mp\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 20)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# module unload oracle-jdk/1.7_64bit\n",
    "# module unload oracle_client/11.2.0.3.0\n",
    "# module load oracle-jdk/1.8_64bit\n",
    "# export _JAVA_OPTIONS=\"-Xmx440G\"\n",
    "\n",
    "# /project/projectdirs/metatlas/projects/mzmine_parameters/MZmine-2.21/startMZmine_Headless.sh /project/projectdirs/metatlas/projects/mzmine_parameters/PseudoC_C18_NEG_job_script_parameters.xmlbpb@edison07:/project/projectdirs/metatlas/projects/mzmine_parameters>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filename = '/global/homes/b/bpb/batch_params/000008_pos_c18_dangl.xml'\n",
    "# with open(filename,'r') as fid:\n",
    "#     xml_str = fid.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = metob.MZMineTask()\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mzm = reload(mzm)\n",
    "xml_str = mzm.get_batch_file_template()\n",
    "d = mzm.xml_to_dict(xml_str)\n",
    "for i,k in enumerate(d['batch']['batchstep']):\n",
    "    print(i,k['@method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task.polarity = 'negative'\n",
    "\n",
    "task.min_peak_duration = 0.025\n",
    "task.max_peak_duration = 30.0\n",
    "task.rt_tol_perfile = 0.015\n",
    "task.rt_tol_multifile = 0.15\n",
    "task.min_peak_height = 1e6\n",
    "task.noise_floor = 3e4\n",
    "task.mz_tolerance = 10.0\n",
    "task.min_sn_ratio = 2.0\n",
    "\n",
    "task.output_csv = '/global/homes/b/bpb/Downloads/20170222_OMALLEY_FUNGUS_NEG_MZMINE_1to10.csv'\n",
    "task.input_xml = '/global/homes/b/bpb/batch_params/20170222_OMALLEY_FUNGUS_NEG_MZMINE_1to10.xml'\n",
    "# task.input_xml = '/project/projectdirs/metatlas/projects/mzmine_parameters/batch_files/test_batch.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groups = dp.select_groups_for_analysis(name = '20151130_LS_Archetypes%C18_pos',\n",
    "#                                        most_recent = True,\n",
    "#                                        remove_empty = True,#'Strain=SB214'\n",
    "#                                        include_list = [], exclude_list = ['QC', 'Blank','L2B56','HA26','HA21','L2B49','D1B20A','L2B47','L1B44','L2B36', 'L2B57', 'HD36','HC17', 'HD72', 'L1B56','HD65'])#['QC','Blank'])\n",
    "# files = []\n",
    "# for g in groups:\n",
    "#     for f in g.items:\n",
    "#         files.append(f)\n",
    "# task.lcmsruns = files\n",
    "# new_d = mzm.replace_files(d,list(pd.unique([f.mzml_file for f in task.lcmsruns])))\n",
    "# list(pd.unique([f.name for f in task.lcmsruns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = metob.retrieve('Lcmsruns',name = '%NEG%UV_Fungus_1to10%102040%',username='*')\n",
    "# files = metob.retrieve('Lcmsruns',hdf5_file = '%neg%coelicolor_media%day6%',username='*')\n",
    "# files = [f for f in files if not '1to10' in f.name]\n",
    "task.lcmsruns = files\n",
    "new_d = mzm.replace_files(d,list(pd.unique([f.mzml_file for f in task.lcmsruns])))\n",
    "list(pd.unique([f.name for f in task.lcmsruns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task.mzmine_launcher = mzm.get_latest_mzmine_binary()\n",
    "new_d = mzm.configure_mass_detection(new_d,task.noise_floor)\n",
    "new_d = mzm.configure_chromatogram_builder(new_d,task.min_peak_duration,task.min_peak_height,task.mz_tolerance)\n",
    "new_d = mzm.configure_peak_deconvolution(new_d,task.min_peak_height,task.min_sn_ratio,task.min_peak_duration,task.max_peak_duration)\n",
    "new_d = mzm.configure_isotope_adduct_fragment_search(new_d,task.mz_tolerance,task.rt_tol_perfile,task.polarity,task.min_peak_height)\n",
    "new_d = mzm.configure_join_aligner(new_d,task.mz_tolerance,task.rt_tol_multifile)\n",
    "new_d = mzm.configure_duplicate_filter(new_d,task.mz_tolerance,task.rt_tol_perfile)\n",
    "new_d = mzm.configure_gap_filling(new_d,task.mz_tolerance)\n",
    "new_d = mzm.configure_csv_output(new_d,task.output_csv)\n",
    "\n",
    "t = mzm.dict_to_etree(new_d)\n",
    "mzm.indent_tree(t)\n",
    "xml_batch_str = mzm.tree_to_xml(t,filename=task.input_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df = metob.to_dataframe([task])\n",
    "df = df[[c for c in df.columns if not 'lcmsruns' in c]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo: create scripts at nersc by editing the startmzmine_Linux script.\n",
    "# todo: create in mzmine_helpers.py a start task that automatically\n",
    "#     defines a unique filename for batch job and output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('%s %s'%(task.mzmine_launcher,task.input_xml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "* make fileinfo sheet\n",
    "* create groups\n",
    "* select groups\n",
    "* __configure mzmine batch job__\n",
    "\n",
    "```\n",
    "1. replace files with selected files\n",
    "2. replace ppm instances with specified ppm\n",
    "3. replace retention time instances with specified ppm\n",
    "4. add/remove adducts\n",
    "5. generate metatlas entry for task\n",
    "```\n",
    "\n",
    "* deploy mzmine batch job\n",
    "* check status of mzmine batch job\n",
    "* import results of mzmine batch job\n",
    "* configure analysis\n",
    "* perform analysis\n",
    "* select/remove rows from results based on analysis\n",
    "* create atlas from results\n",
    "* get data using metatlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '/global/homes/b/bpb/batch_params/000008_pos_c18_dangl.xml'\n",
    "with open(filename,'r') as fid:\n",
    "    xml_str = fid.read()\n",
    "# xml_str\n",
    "e = ET.XML(xml_str)\n",
    "\n",
    "d = etree_to_dict(e)\n",
    "\n",
    "for k in d['batch']['batchstep']:\n",
    "    print(k['@method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(ET.tostring(dict_to_etree(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mzm = reload(mzm)\n",
    "mzmine_output_file = '/global/u2/b/bpb/Downloads/20170222_OMALLEY_FUNGUS_NEG_MZMINE_1to10.csv'\n",
    "df,original_mzmine = mzm.metatlas_formatted_atlas_from_mzmine_output(mzmine_output_file,'positive',\n",
    "                                                                     make_atlas=False,min_rt=0.55,\n",
    "                                                                    remove_fragments=False,\n",
    "                                                                    remove_adducts=False,\n",
    "                                                                    remove_clusters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('/global/homes/b/bpb/Downloads/20170222_OMALLEY_FUNGUS_NEG_MZMINE_1to10_METATLAS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_mzmine.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_super = df[[c for c in df.columns if not 'super' in c]]\n",
    "# df_super = df_super[[c for c in df_super.columns if not 'kana' in c]]\n",
    "# df_super = df_super[[c for c in df_super.columns if not 'max_intensity' in c]]\n",
    "# df_super = df_super[[c for c in df_super.columns if not 'Excontrol' in c]]\n",
    "# df_super = df_super[[c for c in df_super.columns if not 'adduct' in c]]\n",
    "\n",
    "# df_super.set_index(['label','mz','mz_tolerance','rt_peak','rt_min','rt_max','inchi_key','detected_polarity'],inplace=True)\n",
    "# df_super.columns = [''.join(c.split('_')[2:3]) if 'pellet' in c else c for c in df_super.columns ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_super = df[[c for c in df.columns if not 'pellet' in c]]\n",
    "df_super = df_super[[c for c in df_super.columns if not 'kana' in c]]\n",
    "df_super = df_super[[c for c in df_super.columns if not 'max_intensity' in c]]\n",
    "df_super = df_super[[c for c in df_super.columns if not 'Excontrol' in c]]\n",
    "df_super = df_super[[c for c in df_super.columns if not 'adduct' in c]]\n",
    "df_super['rt_min'] = df_super['rt_peak'] - 0.2\n",
    "df_super.set_index(['label','mz','mz_tolerance','rt_peak','rt_min','rt_max','inchi_key','detected_polarity'],inplace=True)\n",
    "df_super.columns = [''.join(c.split('_')[2:3]) if 'super' in c else c for c in df_super.columns ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group1 = df_super[[c for c in df_super.columns if c == 'LB']]\n",
    "group2 = df_super[[c for c in df_super.columns if c == 'PS']]\n",
    "\n",
    "# group2 = df[df['group'] == 'GROUP2']['data'].astype(float)\n",
    "\n",
    "t, p = ttest_ind(group1.T, group2.T)\n",
    "\n",
    "stats_df = pd.DataFrame(index=df_super.index)\n",
    "stats_df['p_value'] = p\n",
    "stats_df['t_score'] = t\n",
    "stats_df['log2_fold_change'] = group2.min(axis=1).apply(lambda x: np.log2(x+1)) - \\\n",
    "                                group1.max(axis=1).apply(lambda x: np.log2(x+1)) \n",
    "stats_df['in_control'] = group1.median(axis=1) > 1e5\n",
    "stats_df['median_control'] = group1.median(axis=1)\n",
    "stats_df['median_treatment'] = group2.median(axis=1)\n",
    "stats_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "stats_df['log2_fold_change'].hist(bins=100)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('LOG2 Fold Change')\n",
    "ax.set_ylabel('#features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "ax.plot(stats_df['log2_fold_change'],stats_df['p_value'],'.')\n",
    "# stats_df['fold_change'].apply(lambda x: np.log2(x+1)).hist(bins=100)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('LOG2 fold change')\n",
    "ax.set_ylabel('p_value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_df = stats_df[(stats_df['log2_fold_change']>7) & (stats_df['median_treatment']>1e5)]\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "# color_map = {filtered_df.log2_fold_change.min():\"r\", filtered_df.log2_fold_change.max():\"g\"} \n",
    "# z_as_colors = map(color_map.get, filtered_df.log2_fold_change) \n",
    "sc = ax.scatter(filtered_df.index.get_level_values('mz'),\n",
    "                filtered_df.index.get_level_values('rt_peak'),\n",
    "                c = filtered_df.log2_fold_change)\n",
    "# stats_df['fold_change'].apply(lambda x: np.log2(x+1)).hist(bins=100)\n",
    "# ax.set_yscale('log')\n",
    "plt.colorbar(sc)\n",
    "ax.set_xlabel('mz')\n",
    "ax.set_ylabel('rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (~stats_df['in_control']) & \n",
    "filtered_df = stats_df[(stats_df['log2_fold_change']>7) & (stats_df['median_treatment']>3e5)]\n",
    "print filtered_df.shape\n",
    "# pd.options.display.precision = 5\n",
    "# pd.set_option('display.max',200)\n",
    "filtered_df.sort_values('log2_fold_change', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_super.iloc[df_super.index.get_level_values('label') == '754.3994@3.75']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# filtered_df.index.names\n",
    "df = pd.DataFrame(columns=filtered_df.index.names)\n",
    "for i,row in enumerate(filtered_df.index.get_values()):\n",
    "    for j,c in enumerate(df.columns):\n",
    "        df.loc[i,c] = row[j]\n",
    "# df.columns = \n",
    "# filtered_df.index.get_values()\n",
    "# #.reset_index(level=[0,1,2])\n",
    "# atlas_df = atlas_df[atlas_df.columns[:6]]\n",
    "# # atlas_df.reset_index(inplace=True)\n",
    "# # atlas_df = atlas_df[[]]\n",
    "# # atlas_df.reset_index(inplace=True)\n",
    "# atlas_df.fillna('')\n",
    "# atlas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myAtlas = dp.make_atlas_from_spreadsheet(df,'20170406_ions_made_psimiae_in_LB_pos_c18',filetype='dataframe',\n",
    "                                       sheetname='',\n",
    "                                       polarity = 'positive',\n",
    "                                       store=True,\n",
    "                                      mz_tolerance = 10)\n",
    "atlas_df = ma_data.make_atlas_df(myAtlas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "groups = dp.select_groups_for_analysis(name = '%rexmalm_pos_super%',\n",
    "                                       most_recent = True,\n",
    "                                       remove_empty = True,#'Strain=SB214'\n",
    "                                       include_list = [], exclude_list = [],)#['QC','Blank'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for g in groups:\n",
    "    for i in g.items:\n",
    "        print i.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for my_group in groups:\n",
    "    for my_file in my_group.items:\n",
    "        all_files.append((my_file,my_group,atlas_df,myAtlas))\n",
    "        \n",
    "pool = mp.Pool(processes=min(10, len(all_files)))\n",
    "# from metatlas.helpers.metatlas_get_data_helper_fun import get_data_for_atlas_df_and_file\n",
    "metatlas_dataset = pool.map(ma_data.get_data_for_atlas_df_and_file, all_files)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "#If you're code crashes here, make sure to terminate any processes left open.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dir = '/global/homes/b/bpb/Downloads/psim_c18_important_pos_super/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "atlas_identifications = dp.export_atlas_to_spreadsheet(myAtlas,os.path.join(output_dir,'atlas_export.csv'))\n",
    "# dp = reload(dp)\n",
    "# atlas_identifications = dp.export_atlas_to_spreadsheet(myAtlas,'%s/sheets/%s.csv'%(plot_location_label,myAtlas.name))\n",
    "peak_height = dp.make_output_dataframe(input_fname = '',input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_height' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "# peak_area = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='peak_area' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "# mz_peak = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "# rt_peak = dp.make_output_dataframe(input_fname = my_file, input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [],fieldname='rt_peak' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "# mz_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='mz_centroid' , output_loc=os.path.join(output_dir,'sheets'))\n",
    "# rt_centroid = dp.make_output_dataframe(input_fname = my_file,input_dataset = metatlas_dataset,include_lcmsruns = [],exclude_lcmsruns = [], fieldname='rt_centroid' , output_loc=os.path.join(output_dir,'sheets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_height.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "peak_height.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from scipy import cluster\n",
    "# mat = peak_height.as_matrix()\n",
    "# mat[np.isnan(mat)] = np.nanmin(mat)\n",
    "# labels = cluster.hierarchy.fclusterdata(mat,0.2,criterion='distance',method='average',metric='correlation')\n",
    "# results = pd.DataFrame(data=labels, columns=['cluster'], index=peak_height.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_height.index = ['@'.join(c.split('_')[:2]).replace('p','.') for c in peak_height.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peak_height.columns = peak_height.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_height.columns = ['_'.join(c.split('_')[14:18]) for c in peak_height.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_height = peak_height.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# norm_peak_height = peak_height.copy()\n",
    "# norm_peak_height = norm_peak_height.apply(lambda x: x / x.max())\n",
    "# norm_peak_height.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_height.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# norm_peak_height.columns.sort_values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = pd.DataFrame()\n",
    "for c in peak_height.columns.sort_values():\n",
    "    sf[c] = peak_height[c]\n",
    "for i,row in sf.iterrows():\n",
    "    sf.loc[i,:] = row/row.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = plt.colormaps()\n",
    "\n",
    "for i,c in enumerate(cm):\n",
    "    print i,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,r in sf.iterrows():\n",
    "    print r.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The returned object has a savefig method that should be used if you want to save the figure object without clipping the dendrograms.\n",
    "\n",
    "# To access the reordered row indices, use: clustergrid.dendrogram_row.reordered_ind\n",
    "\n",
    "# Column indices, use: clustergrid.dendrogram_col.reordered_ind\n",
    "\n",
    "g.dendrogram_row.reordered_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cmap = cm[148]\n",
    "# cmap = sns.light_palette(as_cmap=True)\n",
    "# cmap = sns.diverging_palette(h_neg=210, h_pos=350, s=90, l=30, as_cmap=True)\n",
    "# g  =sns.clustermap(peak_height.apply(lambda x: (x+1)**0.25),metric='correlation',figsize=(25,25),cmap=cmap)\n",
    "# g  =sns.clustermap(peak_height.apply(lambda x: np.log10(x+1)),metric='correlation',figsize=(25,25))\n",
    "g  =sns.clustermap(sf,metric='euclidean',figsize=(30,18),cmap=cmap,col_cluster=True)\n",
    "plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)  # For y axis\n",
    "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=90) # For x axis\n",
    "plt.show()\n",
    "# # http://seaborn.pydata.org/generated/seaborn.clustermap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# zscore = lambda x: (x - stats.nanmean(x)) / stats.nanstd(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,3,figsize=(20,30))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "#     row = peak_height.iloc[[i]]\n",
    "#     c = 0\n",
    "#     vals = []\n",
    "#     for k,v in row.to_dict().items():\n",
    "#         vals.append(v.items()[0][-1])\n",
    "#     v = np.asarray(vals)\n",
    "# #     v = v - np.nanmin(v)\n",
    "# #     v = v / np.nanmax(v)\n",
    "#     v[np.isnan(v)] = np.nanmin(v)\n",
    "#     plt.plot(v,'.-')\n",
    "#     plt.title(myAtlas.compound_identifications[i].name)\n",
    "#     plt.gca().set_yscale('log')\n",
    "# #     ax.set_yscale('log')\n",
    "# plt.tight_layout()\n",
    "# # for i,row in peak_height.iterrows():\n",
    "\n",
    "    \n",
    "# # peak_height.iloc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MetAtlas 2.7",
   "language": "python",
   "name": "metatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
